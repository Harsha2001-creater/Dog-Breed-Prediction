{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcb09d25",
   "metadata": {},
   "source": [
    "### Importing Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6db5785",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc72d97",
   "metadata": {},
   "source": [
    "### Creating Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e68559b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MyProject\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0537540d",
   "metadata": {},
   "source": [
    "### Initializing a SparkSession with configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "941e5408",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"CSVtoMongoDB\") \\\n",
    "    .config(\"spark.mongodb.output.uri\", \"mongodb://localhost:27017/flights.cleaned\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.12:3.0.1\") \\\n",
    "    .config(\"spark.hadoop.fs.AbstractFileSystem.s3a.impl\", \"org.apache.hadoop.fs.LocalFileSystem\") \\\n",
    "    .config(\"spark.sql.catalogImplementation\", \"in-memory\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7b3564",
   "metadata": {},
   "source": [
    "### Reading Data using Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e53940c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = {\n",
    "    2009: \"C:/Users/msrih/Downloads/UMBC CLASSES/603/Data Sets/2009.csv\",\n",
    "    2010: \"C:/Users/msrih/Downloads/UMBC CLASSES/603/Data Sets/2010.csv\",\n",
    "    2011: \"C:/Users/msrih/Downloads/UMBC CLASSES/603/Data Sets/2011.csv\",\n",
    "    2012: \"C:/Users/msrih/Downloads/UMBC CLASSES/603/Data Sets/2012.csv\",\n",
    "    2013: \"C:/Users/msrih/Downloads/UMBC CLASSES/603/Data Sets/2013.csv\",\n",
    "    2014: \"C:/Users/msrih/Downloads/UMBC CLASSES/603/Data Sets/2014.csv\",\n",
    "    2015: \"C:/Users/msrih/Downloads/UMBC CLASSES/603/Data Sets/2015.csv\",\n",
    "    2016: \"C:/Users/msrih/Downloads/UMBC CLASSES/603/Data Sets/2016.csv\",\n",
    "    2017: \"C:/Users/msrih/Downloads/UMBC CLASSES/603/Data Sets/2017.csv\",\n",
    "    2018: \"C:/Users/msrih/Downloads/UMBC CLASSES/603/Data Sets/2018.csv\"\n",
    "}\n",
    "\n",
    "dfs = {}  # Dictionary to store DataFrames for each year\n",
    "\n",
    "for year, file_path in file_paths.items():\n",
    "    dfs[year] = spark.read.csv(file_path, header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b919a768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------\n",
      " FL_DATE             | 2009-01-01 \n",
      " OP_CARRIER          | XE         \n",
      " OP_CARRIER_FL_NUM   | 1204       \n",
      " ORIGIN              | DCA        \n",
      " DEST                | EWR        \n",
      " CRS_DEP_TIME        | 1100       \n",
      " DEP_TIME            | 1058.0     \n",
      " DEP_DELAY           | -2.0       \n",
      " TAXI_OUT            | 18.0       \n",
      " WHEELS_OFF          | 1116.0     \n",
      " WHEELS_ON           | 1158.0     \n",
      " TAXI_IN             | 8.0        \n",
      " CRS_ARR_TIME        | 1202       \n",
      " ARR_TIME            | 1206.0     \n",
      " ARR_DELAY           | 4.0        \n",
      " CANCELLED           | 0.0        \n",
      " CANCELLATION_CODE   | NULL       \n",
      " DIVERTED            | 0.0        \n",
      " CRS_ELAPSED_TIME    | 62.0       \n",
      " ACTUAL_ELAPSED_TIME | 68.0       \n",
      " AIR_TIME            | 42.0       \n",
      " DISTANCE            | 199.0      \n",
      " CARRIER_DELAY       | NULL       \n",
      " WEATHER_DELAY       | NULL       \n",
      " NAS_DELAY           | NULL       \n",
      " SECURITY_DELAY      | NULL       \n",
      " LATE_AIRCRAFT_DELAY | NULL       \n",
      " Unnamed: 27         | NULL       \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs[2009].show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa5fc0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type of the loaded dataframes:\n",
      "dfs[2009]: <class 'pyspark.sql.dataframe.DataFrame'>\n",
      "dfs[2010]: <class 'pyspark.sql.dataframe.DataFrame'>\n",
      "dfs[2011]: <class 'pyspark.sql.dataframe.DataFrame'>\n",
      "dfs[2012]: <class 'pyspark.sql.dataframe.DataFrame'>\n",
      "dfs[2013]: <class 'pyspark.sql.dataframe.DataFrame'>\n",
      "dfs[2014]: <class 'pyspark.sql.dataframe.DataFrame'>\n",
      "dfs[2015]: <class 'pyspark.sql.dataframe.DataFrame'>\n",
      "dfs[2016]: <class 'pyspark.sql.dataframe.DataFrame'>\n",
      "dfs[2017]: <class 'pyspark.sql.dataframe.DataFrame'>\n",
      "dfs[2018]: <class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Data type of the loaded dataframes:\")\n",
    "for year, df in dfs.items():\n",
    "    print(f'dfs[{year}]: {type(df)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3587e79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "# List comprehension to extract DataFrame values from the dictionary\n",
    "dfs_list = [dfs[year] for year in dfs]\n",
    "\n",
    "# Concatenating all DataFrames into a single DataFrame\n",
    "df = reduce(DataFrame.unionAll, dfs_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1aa1905f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- FL_DATE: date (nullable = true)\n",
      " |-- OP_CARRIER: string (nullable = true)\n",
      " |-- OP_CARRIER_FL_NUM: integer (nullable = true)\n",
      " |-- ORIGIN: string (nullable = true)\n",
      " |-- DEST: string (nullable = true)\n",
      " |-- CRS_DEP_TIME: double (nullable = true)\n",
      " |-- DEP_TIME: double (nullable = true)\n",
      " |-- DEP_DELAY: double (nullable = true)\n",
      " |-- TAXI_OUT: double (nullable = true)\n",
      " |-- WHEELS_OFF: double (nullable = true)\n",
      " |-- WHEELS_ON: double (nullable = true)\n",
      " |-- TAXI_IN: double (nullable = true)\n",
      " |-- CRS_ARR_TIME: double (nullable = true)\n",
      " |-- ARR_TIME: double (nullable = true)\n",
      " |-- ARR_DELAY: double (nullable = true)\n",
      " |-- CANCELLED: double (nullable = true)\n",
      " |-- CANCELLATION_CODE: string (nullable = true)\n",
      " |-- DIVERTED: double (nullable = true)\n",
      " |-- CRS_ELAPSED_TIME: double (nullable = true)\n",
      " |-- ACTUAL_ELAPSED_TIME: double (nullable = true)\n",
      " |-- AIR_TIME: double (nullable = true)\n",
      " |-- DISTANCE: double (nullable = true)\n",
      " |-- CARRIER_DELAY: double (nullable = true)\n",
      " |-- WEATHER_DELAY: double (nullable = true)\n",
      " |-- NAS_DELAY: double (nullable = true)\n",
      " |-- SECURITY_DELAY: double (nullable = true)\n",
      " |-- LATE_AIRCRAFT_DELAY: double (nullable = true)\n",
      " |-- Unnamed: 27: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#schema of df2008\n",
    "df.printSchema()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b6bfd5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61556964"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d3e554d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3d5fddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FL_DATE',\n",
       " 'OP_CARRIER',\n",
       " 'OP_CARRIER_FL_NUM',\n",
       " 'ORIGIN',\n",
       " 'DEST',\n",
       " 'CRS_DEP_TIME',\n",
       " 'DEP_TIME',\n",
       " 'DEP_DELAY',\n",
       " 'TAXI_OUT',\n",
       " 'WHEELS_OFF',\n",
       " 'WHEELS_ON',\n",
       " 'TAXI_IN',\n",
       " 'CRS_ARR_TIME',\n",
       " 'ARR_TIME',\n",
       " 'ARR_DELAY',\n",
       " 'CANCELLED',\n",
       " 'CANCELLATION_CODE',\n",
       " 'DIVERTED',\n",
       " 'CRS_ELAPSED_TIME',\n",
       " 'ACTUAL_ELAPSED_TIME',\n",
       " 'AIR_TIME',\n",
       " 'DISTANCE',\n",
       " 'CARRIER_DELAY',\n",
       " 'WEATHER_DELAY',\n",
       " 'NAS_DELAY',\n",
       " 'SECURITY_DELAY',\n",
       " 'LATE_AIRCRAFT_DELAY',\n",
       " 'Unnamed: 27']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c12f740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-----------------------\n",
      " FL_DATE             | 0        \n",
      " OP_CARRIER          | 0        \n",
      " OP_CARRIER_FL_NUM   | 0        \n",
      " ORIGIN              | 0        \n",
      " DEST                | 0        \n",
      " CRS_DEP_TIME        | 1        \n",
      " DEP_TIME            | 935723   \n",
      " DEP_DELAY           | 940675   \n",
      " TAXI_OUT            | 963901   \n",
      " WHEELS_OFF          | 963896   \n",
      " WHEELS_ON           | 997016   \n",
      " TAXI_IN             | 997015   \n",
      " CRS_ARR_TIME        | 2        \n",
      " ARR_TIME            | 997015   \n",
      " ARR_DELAY           | 1121351  \n",
      " CANCELLED           | 0        \n",
      " CANCELLATION_CODE   | 60583755 \n",
      " DIVERTED            | 0        \n",
      " CRS_ELAPSED_TIME    | 60       \n",
      " ACTUAL_ELAPSED_TIME | 1118754  \n",
      " AIR_TIME            | 1118753  \n",
      " DISTANCE            | 0        \n",
      " CARRIER_DELAY       | 50166224 \n",
      " WEATHER_DELAY       | 50166224 \n",
      " NAS_DELAY           | 50166224 \n",
      " SECURITY_DELAY      | 50166224 \n",
      " LATE_AIRCRAFT_DELAY | 50166224 \n",
      " Unnamed: 27         | 61556964 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#To check the number of null values\n",
    "from pyspark.sql.functions import col, isnan, unix_timestamp, when, count\n",
    "\n",
    "uniondf2 = df.select([\n",
    "    count(when(\n",
    "        col(c).contains('None') | col(c).contains('NULL') | (col(c) == 'NA') | col(c).isNull() | isnan(c),\n",
    "        c)\n",
    "    ).alias(c) if c != 'FL_DATE' else\n",
    "    count(when(\n",
    "        col(c).contains('None') | col(c).contains('NULL') | (col(c) == 'NA') | col(c).isNull() | isnan(unix_timestamp(c)),\n",
    "        c)\n",
    "    ).alias(c)\n",
    "    for c in df.columns\n",
    "])\n",
    "\n",
    "uniondf2.show(vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b43d2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
