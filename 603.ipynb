{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMFrltyH4Mp34LzguLpBmIz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harsha2001-creater/603/blob/main/603.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzN3kPOxrhne",
        "outputId": "425824fb-1b75-4ece-e7fd-c335a617f7d3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=c0d2ac57c846054773fb23d6478b3410f228f5d21dea5c3ce3558145b918fcff\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6erJsbdvq0n4"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, IntegerType, NullType\n",
        "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml.feature import StandardScaler, Imputer\n",
        "from pyspark.sql import functions as f\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql import SQLContext\n",
        "import pyspark.ml.feature as ftr\n",
        "import pyspark.ml as ml\n",
        "\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.classification import GBTClassifier\n",
        "from pyspark.mllib.linalg.distributed import RowMatrix\n",
        "from pyspark.ml.tuning import ParamGridBuilder\n",
        "from pyspark.ml.tuning import CrossValidator\n",
        "from pyspark.ml.tuning import TrainValidationSplit\n",
        "from pyspark.ml import PipelineModel\n",
        "from pyspark.mllib.linalg import Vectors\n",
        "from pyspark.ml.feature import PCA\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create a SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"FlightDelayPrediction\") \\\n",
        "    .getOrCreate()\n"
      ],
      "metadata": {
        "id": "MB-Z3RUkrR11"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CSV file into a DataFrame\n",
        "airlines = spark.read.csv(\"Airline_Delay_Cause.csv\", header=True, inferSchema=True)\n",
        "f'{airlines.count():,}'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "KanAM-TgsCsP",
        "outputId": "74138987-eab7-4530-d560-607e7b2fd6b7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'142,972'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(airlines)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "MrRN9WIfsx2e",
        "outputId": "edf5e526-fc36-43fd-b28b-ca541d2371e7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "DataFrame[year: int, month: int, carrier: string, carrier_name: string, airport: string, airport_name: string, arr_flights: double, arr_del15: double, carrier_ct: double, weather_ct: double, nas_ct: double, security_ct: double, late_aircraft_ct: double, arr_cancelled: double, arr_diverted: double, arr_delay: double, carrier_delay: double, weather_delay: double, nas_delay: double, security_delay: double, late_aircraft_delay: double]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "airlines.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-XkYvxXyBRs",
        "outputId": "a308ec5f-3123-4a4f-dc4c-23bed726999c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(year=2024, month=1, carrier='9E', carrier_name='Endeavor Air Inc.', airport='ABE', airport_name='Allentown/Bethlehem/Easton, PA: Lehigh Valley International', arr_flights=80.0, arr_del15=16.0, carrier_ct=4.78, weather_ct=2.56, nas_ct=1.98, security_ct=0.0, late_aircraft_ct=6.68, arr_cancelled=0.0, arr_diverted=2.0, arr_delay=1071.0, carrier_delay=165.0, weather_delay=326.0, nas_delay=62.0, security_delay=0.0, late_aircraft_delay=518.0)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B-1xClYYyE-l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}